---
title: "doublet_finder_matrix_extraction"
output: html_document
date: "2025-06-26"
---
R markdown file for dissociated scRNA-seq datasets that:
  1) runs QC metric thresholding (total UMIs, features, %mitochondrial)
  2) runs doubletFinder
  3) builds out metadata fields
  4) generates variable gene lists
  5) extracts sparse gene expression matrices)

Contains code that is commented out for running more than one sample dataset.

***Input for this analysis requires a gene x counts matrix from STAR-based alignment with NCBI RefSeq annotations for each rabies-infected dataset. Alternative annotations can be used, but steps to calculate %mitochondrial genes will fail. 

***If running multiple experimental datasets, you can calculate variable gene sets from pooled data. To accomplish this, use chunks 10+11. If only running one dataset, SKIP chunks 10+11, and just run chunk 12 

Input files:
GEX_with_raw_counts.h5ad: h5ad-compressed gene expression matrix from a reference dataset
tutorial_sample_matrix: standard gene expression matrix output from Pipseeker alignment for an experimental dataset

Output files:
tutorial_reference_metadata.csv: metadata file exported directly from reference dataset publication.
tutorial_reference_variable_genes.csv: top 3000 variable genes from reference dataset
tutorial_reference_matrix.csv: sparse matrix from reference dataset extracted from h5ad object

tutorial_sample_variable_genes.csv: top 3000 variable genes calculated for sample datasets
tutorial_sample_matrix_postdf.csv: sparse matrix from sample dataset after filtering doublets with doubletFinder



Last amended by Maddie Urbanek, 8/14/25

```{r setup}
#Lockfile containing list of dependencies and their versions is available at https://github.com/MEUrbanek/centroid_mapping. This lockfile does not contain development dependencies (i.e. devtools)!

#Load in libraries
library(devtools)
library(BiocManager)
library(DESeq2)
library(Matrix)
library(Seurat)
library(SeuratObject)
library(dplyr)
library(patchwork)
library(rhdf5)
library(ggpubr)
library(tidyverse)
library(ggplot2)
library(hdf5r)
library(EnhancedVolcano)
library(dittoSeq)
library(sctransform)
library(glmGamPoi)
library(cowplot)
library(harmony)
library(DoubletFinder)
library(clusterProfiler)
library(dittoSeq)
library(UCell)
library(scCustomize)
library(DoubletFinder)
library(schard)

#Set seed
set.seed(13)

#Set working directory to where data is stored
setwd('~/centroid_mapping/data/')
```

```{r read in reference dataset}
#Load unzipped H5 file using schard
snhx = schard::h5ad2seurat("./GEX_with_raw_counts.h5ad")

#Verify that UMAP embeddings are present
DimPlot(snhx)

#Subset dataset down to midgestation ('Second_trimester' in snhx$Group)
ref=subset(snhx, subset = Group == 'Second_trimester')

#Plot reference atlas with annotations
Idents(object = ref) <- "type"
DimPlot(ref)

#Convert object to Seurat V
ref<-UpdateSeuratObject(ref)

#Identify top 3000 variable features as described in https://github.com/complexdisease/Human_Cortex_Dev_Multiome/blob/main/RScript/00_snMultiome_data_integration.R, which utilizes Seurat's FindIntegrationAnchors function to run FindVariableFeatures on default settings, 3000 features
normalized_ref <- NormalizeData(ref)
normalized_ref <- FindVariableFeatures(normalized_ref, nfeatures=3000)

#Send variable genes from reference dataset to .csv file
ref_var_genes<-normalized_ref@assays$RNA@var.features
write.csv(ref_var_genes,'tutorial_reference_variable_genes.csv')

#Extracting sparse matrix from Wang 2025
write.csv(ref@assays$RNA@counts,'tutorial_reference_matrix.csv')

#And cluster annotations from Wang 2025
write.csv(ref@meta.data,'tutorial_reference_metadata.csv')
``` 

```{r load in datasets}
#To process in Seurat, raw count matrices generated by Pipseeker are loaded in and converted into Seurat objects for each dataset. 

#Read each dataset into R using Read10X function from Seurat
  ##Pip-seq output matrix is in 10X format
  ##Used sensitivity 5 filtered matrix

  #SADB19 whole cell from February/March 2024:
#s1<-Read10X('./feb_2024/s1/txn/pipseeker_filtered')
#s2<-Read10X('./feb_2024/s2/txn/pipseeker_filtered')
#s3<-Read10X('./feb_2024/s3/txn/pipseeker_filtered')
#s4<-Read10X('./feb_2024/s4/txn/pipseeker_filtered')
#s5<-Read10X('./feb_2024/s5/txn/pipseeker_filtered')

  #CVS-N2C whole cell and nuclei, paired cases from March/April 2024:
#c1<-Read10X('./apr_2024/c1/txn/pipseeker_filtered')
#c2<-Read10X('./apr_2024/c2/txn/pipseeker_filtered')
#n1<-Read10X('./apr_2024/n1/txn/pipseeker_filtered')
#n2<-Read10X('./apr_2024/n2/txn/pipseeker_filtered')

  #Additional CVS-N2C nuclei from January-April 2025:
#n3<-Read10X('./apr_2025/n3/txn/pipseeker_filtered')
#n4<-Read10X('./apr_2025/n4/txn/pipseeker_filtered')

  #Pooled uninfected cells from March/April 2024:
u1<-Read10X('tutorial_sample_matrix')

#Create Seurat Objects
#s1<-CreateSeuratObject(counts = s1)
#s2<-CreateSeuratObject(counts = s2)
#s3<-CreateSeuratObject(counts = s3)
#s4<-CreateSeuratObject(counts = s4)
#s5<-CreateSeuratObject(counts = s5)
#c1<-CreateSeuratObject(counts = c1)
#c2<-CreateSeuratObject(counts = c2)
#n1<-CreateSeuratObject(counts = n1)
#n2<-CreateSeuratObject(counts = n2)
#n3<-CreateSeuratObject(counts = n3)
#n4<-CreateSeuratObject(counts = n4)
u1<-CreateSeuratObject(counts = u1)
```

```{r calculate percent mitochondrial genes for each dataset}
#Pull all genes that start with "MT-" (indicating that they're mitochondrial), and then calculate what percentage of counts within that cell correspond to those genes

###This is only compatible with human NCBI RefSeq annotations--if using Ensembl or a different species, will need to change pattern specifier (ex: "^mt-" for mice) or use a collated gene list

#s1[["percent.mt"]] <- PercentageFeatureSet(s1, pattern = "^MT-")
#s2[["percent.mt"]] <- PercentageFeatureSet(s2, pattern = "^MT-")
#s3[["percent.mt"]] <- PercentageFeatureSet(s3, pattern = "^MT-")
#s4[["percent.mt"]] <- PercentageFeatureSet(s4, pattern = "^MT-")
#s5[["percent.mt"]] <- PercentageFeatureSet(s5, pattern = "^MT-")
#c1[["percent.mt"]] <- PercentageFeatureSet(c1, pattern = "^MT-")
#c2[["percent.mt"]] <- PercentageFeatureSet(c2, pattern = "^MT-")
#n1[["percent.mt"]] <- PercentageFeatureSet(n1, pattern = "^MT-")
#n2[["percent.mt"]] <- PercentageFeatureSet(n2, pattern = "^MT-")
#n3[["percent.mt"]] <- PercentageFeatureSet(n3, pattern = "^MT-")
#n4[["percent.mt"]] <- PercentageFeatureSet(n4, pattern = "^MT-")
u1[["percent.mt"]] <- PercentageFeatureSet(u1, pattern = "^MT-")
```

```{r add dataset ID}
#Dataset ID, which enables pooling of datasets
#s1[["datasetid"]] <- "s1"
#s2[["datasetid"]] <- "s2"
#s3[["datasetid"]] <- "s3"
#s4[["datasetid"]] <- "s4"
#s5[["datasetid"]] <- "s5"
#c1[["datasetid"]] <- "c1"
#c2[["datasetid"]] <- "c2"
#n1[["datasetid"]] <- "n1"
#n2[["datasetid"]] <- "n2"
#n3[["datasetid"]] <- "n3"
#n4[["datasetid"]] <- "n4"
u1[["datasetid"]] <- "u1"
```

```{r add more metadata}
#Strain of rabies used for each dataset
#s1[["virus"]] <- "sadb19"
#s2[["virus"]] <- "sadb19"
#s3[["virus"]] <- "sadb19"
#s4[["virus"]] <- "sadb19"
#s5[["virus"]] <- "sadb19"
#c1[["virus"]] <- "cvs"
#c2[["virus"]] <- "cvs"
#n1[["virus"]] <- "cvs"
#n2[["virus"]] <- "cvs"
#n3[["virus"]] <- "cvs"
#n4[["virus"]] <- "cvs"
u1[["virus"]] <- "uninfected"

#Dissociation method
#s1[["modality"]] <- "cell"
#s2[["modality"]] <- "cell"
#s3[["modality"]] <- "cell"
#s4[["modality"]] <- "cell"
#s5[["modality"]] <- "cell"
#c1[["modality"]] <- "cell"
#c2[["modality"]] <- "cell"
#n1[["modality"]] <- "nuc"
#n2[["modality"]] <- "nuc"
#n3[["modality"]] <- "nuc"
#n4[["modality"]] <- "nuc"
u1[["modality"]] <- "cell"

#Reported gestational age
#s1[["age"]] <- "gw21"
#s2[["age"]] <- "gw16"
#s3[["age"]] <- "gw22"
#s4[["age"]] <- "gw20"
#s5[["age"]] <- "gw20"
#c1[["age"]] <- "gw19"
#c2[["age"]] <- "gw21"
#n1[["age"]] <- "gw19"
#n2[["age"]] <- "gw21"
#n3[["age"]] <- "gw22"
#n4[["age"]] <- "gw23"
u1[["age"]] <- "gw16-21"
```

```{r additional qc thresholding}
#Visualize plots based on modalities to determine QC thresholds

#Nuclei datasets first
#nuc_datasets=merge(x = n1, y = c(n2,n3,n4))
#VlnPlot(nuc_datasets,features='nCount_RNA',split.by='datasetid') + scale_y_continuous(limits = c(0,2500))
#VlnPlot(nuc_datasets,features='nFeature_RNA',split.by='datasetid') + scale_y_continuous(limits = c(0,2500))
#VlnPlot(nuc_datasets,features='percent.mt',split.by='datasetid') + scale_y_continuous(limits = c(0,5))

#Then whole cell datasets
#cell_datasets=merge(x = s1, y = c(s2,s3,s4,s5,c1,c2,u1))
#VlnPlot(cell_datasets,features='nCount_RNA',split.by='datasetid') + scale_y_continuous(limits = c(0,5000))
#VlnPlot(cell_datasets,features='nFeature_RNA',split.by='datasetid') + scale_y_continuous(limits = c(0,5000))
#VlnPlot(cell_datasets,features='percent.mt',split.by='datasetid') + scale_y_continuous(limits = c(0,5))

#For single sample only:
VlnPlot(u1, features=c('nCount_RNA','nFeature_RNA','percent.mt'))

#Whole cell datasets are thresholded on >1000 unique genes, 1250 UMIs, and <5% mitochondrial genes (Delgado et al 2022) excluding s1 and s2, which are thresholded at >500 unique genes and UMIs.

#Nuclei datasets are thresholded on >250 unique genes, >300 UMIs, and <1% mitochondrial genes, except for n4 which has high mitochondrial contamination, and n2, which is markedly higher quality than other nuclear datasets
#s1 <- subset(s1, subset = nFeature_RNA > 500 & nCount_RNA > 500 & percent.mt < 5)
#s2 <- subset(s2, subset = nFeature_RNA > 500 & nCount_RNA > 500 & percent.mt < 5)
#s3 <- subset(s3, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 5)
#s4 <- subset(s4, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 5)
#s5 <- subset(s5, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 5)
#c1 <- subset(c1, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 5)
#c2 <- subset(c2, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 5)
#n1 <- subset(n1, subset = nFeature_RNA > 300 & nCount_RNA > 500 & percent.mt < 1)
#Sample n2 has higher nFeature and nCount thresholds to account for improved quality of dataset
#n2 <- subset(n2, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 2)
#n3 <- subset(n3, subset = nFeature_RNA > 300 & nCount_RNA > 300 & percent.mt < 1)
#Sample n4 has higher mitochondrial contamination than expected--raising threshold, but keep in mind after integration
#n4 <- subset(n4, subset = nFeature_RNA > 250 & nCount_RNA > 300 & percent.mt < 5)

u1 <- subset(u1, subset = nFeature_RNA > 1000 & nCount_RNA > 1250 & percent.mt < 5)
```

```{r add dataset ID to cell barcode}
#This will add the dataset ID to the front of each cell barcode to prevent collision of identical barcodes across Pip-seq runs
#It also adds a column to the metadata with the cell barcode, which will be used to match transcriptome to rabies barcodes
#s1 <- RenameCells(s1, 's1')
#s1[["cellbarcode"]] <- s1@assays$RNA@cells[[1]]
#s2 <- RenameCells(s2, 's2')
#s2[["cellbarcode"]] <- s2@assays$RNA@cells[[1]]
#s3 <- RenameCells(s3, 's3')
#s3[["cellbarcode"]] <- s3@assays$RNA@cells[[1]]
#s4 <- RenameCells(s4, 's4')
#s4[["cellbarcode"]] <- s4@assays$RNA@cells[[1]]
#s5 <- RenameCells(s5, 's5')
#s5[["cellbarcode"]] <- s5@assays$RNA@cells[[1]]
#c1 <- RenameCells(c1, 'c1')
#c1[["cellbarcode"]] <- c1@assays$RNA@cells[[1]]
#c2 <- RenameCells(c2, 'c2')
#c2[["cellbarcode"]] <- c2@assays$RNA@cells[[1]]
#n1 <- RenameCells(n1, 'n1')
#n1[["cellbarcode"]] <- n1@assays$RNA@cells[[1]]
#n2 <- RenameCells(n2, 'n2')
#n2[["cellbarcode"]] <- n2@assays$RNA@cells[[1]]
#n3 <- RenameCells(n3, 'n3')
#n3[["cellbarcode"]] <- n3@assays$RNA@cells[[1]]
#n4 <- RenameCells(n4, 'n4')
#n4[["cellbarcode"]] <- n4@assays$RNA@cells[[1]]
u1 <- RenameCells(u1, 'u1')
u1[["cellbarcode"]] <- u1@assays$RNA@cells[[1]]
```

```{r doublet finder}
#Doublet finder is applied independently to each dataset to identify putative multiplets, which can then be subset from downstream analysis

#Write functions to run DoubletFinder on each dataset
#This function requires each dataset to be independently run and processes them using default Seurat parameters
#After running this function, ElbowPlot() should be used to identify dimensions to be input into the following function
standard_seurat_processing <- function(obj) {
  obj_doublet <- obj %>%
    NormalizeData() %>%
    FindVariableFeatures(selection.method = "vst", nfeatures = 3000) %>% 
    ScaleData() %>%
    RunPCA(assay = "RNA", npcs = 50)
}

#This function requires the proccessed Seurat object from above, plus the number of dimensions determined by the elbow plot's inflection point to draw clusters for identification of heterotypic and homotypic doublets
standard_clustering <- function(obj_doublet,dimensions) {
  obj_doublet <- RunUMAP(obj_doublet, dims = 1:dimensions)
  obj_doublet <- FindNeighbors(object = obj_doublet, dims = 1:dimensions)              
  obj_doublet <- FindClusters(object = obj_doublet, resolution = 0.1)
}

#This function requires the proccessed Seurat object from above, plus the number of dimensions determined by the elbow plot's inflection point to do a pk sweep, which is needed to build simulated doublet pool
pk_sweep <- function(obj_doublet,dimensions) {
  sweep.list <- paramSweep(obj_doublet, PCs = 1:dimensions)
  sweep.stats <- summarizeSweep(sweep.list)
  bcmvn <- find.pK(sweep.stats)
  bcmvn.max <- bcmvn[which.max(bcmvn$BCmetric),]
  optimal.pk <- bcmvn.max$pK
  optimal.pk <<- as.numeric(levels(optimal.pk))[optimal.pk]
  annotations <- obj_doublet@meta.data$seurat_clusters
  homotypic.prop <<- modelHomotypic(annotations)
}

#This function requires you to point to the Seurat object and its metadata table in order to calculate expected number of doublets
#Can be skipped if you're using a predicted proportion of multiplets
calculate_expected_doublets <- function(metadata_input) {
    nExp.poi <- round(optimal.pk * nrow(metadata_input))
    nExp.poi.adj <<- round(nExp.poi * (1 - homotypic.prop))
}

#U1
u1 <- standard_seurat_processing(u1)
ElbowPlot(u1)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(u1, dimensions)
u1 <- standard_clustering(u1,dimensions)
calculate_expected_doublets(u1@meta.data)

#Run DoubletFinder on dataset
#Input parameters are the prepped Seurat object, significant PCs, the optimal pK value calculated above, and the threshold for doublet+singlet prediction
#nExp can either be set based on the value calculated using calculate_expected_doublets() or using approximations based on number of cells loaded and reported multiplet rate from company
#For example, Pip-seq predicts a multiplet rate of 5% when loading 5,000 nuclei, so for 500 cells, you'd set nExp to 25
doublet_finder <- doubletFinder(seu = u1, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
u1<-AddMetaData(object = u1, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(u1$doublet_finder))
Idents(u1) <- "doublet_finder"
u1 <- subset(u1, idents = "Singlet")

#Clean up global environment
rm(doublet_finder)
rm(metadata)

#For additional datasets, see chunk 'doubletFinder for additional samples' at the bottom of this markdown file 
```

```{r pool cell and nuclei datasets to calculate variable genes}
#Run this if you want to make variable gene lists based on shared variable genes within certain groups!
cell_datasets=merge(x = s1, y = c(s2,s3,s4,s5,c1,c2,u1))
nuc_datasets=merge(x = n1, y = c(n2,n3,n4))
```

```{r extract top 3000 variable genes from cell and nuc datasets}
#Run this if you pooled datasets in chunk 10: 'pool cell and nuclei datasets to calculate variable genes'
cells <- standard_seurat_processing(cell_datasets)
nuc <- standard_seurat_processing(nuc_datasets)

cells_var_genes=unique(cells@assays$RNA@meta.data$var.features)
cells_var_genes=cells_var_genes[!is.na(cells_var_genes)]

nuc_var_genes=unique(nuc@assays$RNA@meta.data$var.features)
nuc_var_genes=nuc_var_genes[!is.na(nuc_var_genes)]

#Pool all sample gene lists together for single .csv input into centroid_mapping.ipynb
sample_var_genes<- data.frame(cells_var_genes,nuc_var_genes)

#Send variable genes dataframe to .csv file for input into centroid_mapping python script
write.csv(sample_var_genes, 'tutorial_sample_variable_genes.csv')

```

```{r extract variable genes for each dataset}
#Run this if you want to generate variable genes lists for each independent dataset
#Build empty dataframe for sending variable gene lists to
#s1_var_genes=unique(s1@assays$RNA@meta.data$var.features)
#s1_var_genes=s1_var_genes[!is.na(s1_var_genes)]
#s2_var_genes=unique(s2@assays$RNA@meta.data$var.features)
#s2_var_genes=s2_var_genes[!is.na(s2_var_genes)]
#s3_var_genes=unique(s3@assays$RNA@meta.data$var.features)
#s3_var_genes=s3_var_genes[!is.na(s3_var_genes)]
#s4_var_genes=unique(s4@assays$RNA@meta.data$var.features)
#s4_var_genes=s4_var_genes[!is.na(s4_var_genes)]
#s5_var_genes=unique(s5@assays$RNA@meta.data$var.features)
#s5_var_genes=s5_var_genes[!is.na(s5_var_genes)]
#c1_var_genes=unique(c1@assays$RNA@meta.data$var.features)
#c1_var_genes=c1_var_genes[!is.na(c1_var_genes)]
#c2_var_genes=unique(c2@assays$RNA@meta.data$var.features)
#c2_var_genes=c2_var_genes[!is.na(c2_var_genes)]
#n1_var_genes=unique(n1@assays$RNA@meta.data$var.features)
#n1_var_genes=n1_var_genes[!is.na(n1_var_genes)]
#n2_var_genes=unique(n2@assays$RNA@meta.data$var.features)
#n2_var_genes=n2_var_genes[!is.na(n2_var_genes)]
#n3_var_genes=unique(n3@assays$RNA@meta.data$var.features)
#n3_var_genes=n3_var_genes[!is.na(n3_var_genes)]
#n4_var_genes=unique(n4@assays$RNA@meta.data$var.features)
#n4_var_genes=n4_var_genes[!is.na(n4_var_genes)]
u1_var_genes=unique(u1@assays$RNA@meta.data$var.features)
u1_var_genes=u1_var_genes[!is.na(u1_var_genes)]

#sample_var_genes<- data.frame(s1_var_genes,s2_var_genes,s3_var_genes,s4_var_genes,s5_var_genes,c1_var_genes,c2_var_genes,n1_var_genes,n2_var_genes,n3_var_genes,n4_var_genes,u1_var_genes)

#Send variable genes dataframe to .csv file for input into centroid_mapping python script
#write.csv(sample_var_genes, './transcriptome/sample_var_genes.csv')

#For single sample
write.csv(u1_var_genes, 'tutorial_sample_variable_genes.csv')
```

```{r extract sparse matrix for each dataset}
#Each sparse matrix should be extracted independently by dataset!
#s1_sparse=s1@assays$RNA@layers$counts
#cells=rownames(s1@assays$RNA@cells@.Data)
#colnames(s1_sparse)<-cells
#features=rownames(s1@assays$RNA@features@.Data)
#rownames(s1_sparse)<-features

#write.csv(s1_sparse, './filtered_sparse_matrices/s1_sparse.csv') 

#s2_sparse=s2@assays$RNA@layers$counts
#cells=rownames(s2@assays$RNA@cells@.Data)
#colnames(s2_sparse)<-cells
#features=rownames(s2@assays$RNA@features@.Data)
#rownames(s2_sparse)<-features

#write.csv(s2_sparse, './filtered_sparse_matrices/s2_sparse.csv')  

#s3_sparse=s3@assays$RNA@layers$counts
#cells=rownames(s3@assays$RNA@cells@.Data)
#colnames(s3_sparse)<-cells
#features=rownames(s3@assays$RNA@features@.Data)
#rownames(s3_sparse)<-features

#write.csv(s3_sparse, './filtered_sparse_matrices/s3_sparse.csv') 

#s4_sparse=s4@assays$RNA@layers$counts
#cells=rownames(s4@assays$RNA@cells@.Data)
#colnames(s4_sparse)<-cells
#features=rownames(s4@assays$RNA@features@.Data)
#rownames(s4_sparse)<-features

#write.csv(s4_sparse, './filtered_sparse_matrices/s4_sparse.csv') 

#s5_sparse=s5@assays$RNA@layers$counts
#cells=rownames(s5@assays$RNA@cells@.Data)
#colnames(s5_sparse)<-cells
#features=rownames(s5@assays$RNA@features@.Data)
#rownames(s5_sparse)<-features

#write.csv(s5_sparse, './filtered_sparse_matrices/s5_sparse.csv')

#c1_sparse=c1@assays$RNA@layers$counts
#cells=rownames(c1@assays$RNA@cells@.Data)
#colnames(c1_sparse)<-cells
#features=rownames(c1@assays$RNA@features@.Data)
#rownames(c1_sparse)<-features

#write.csv(c1_sparse, './filtered_sparse_matrices/c1_sparse.csv')

#c2_sparse=c2@assays$RNA@layers$counts
#cells=rownames(c2@assays$RNA@cells@.Data)
#colnames(c2_sparse)<-cells
#features=rownames(c2@assays$RNA@features@.Data)
#rownames(c2_sparse)<-features

#write.csv(c2_sparse, './filtered_sparse_matrices/c2_sparse.csv')

#n1_sparse=n1@assays$RNA@layers$counts
#cells=rownames(n1@assays$RNA@cells@.Data)
#colnames(n1_sparse)<-cells
#features=rownames(n1@assays$RNA@features@.Data)
#rownames(n1_sparse)<-features

#write.csv(n1_sparse, './filtered_sparse_matrices/n1_sparse.csv')

#n2_sparse=n2@assays$RNA@layers$counts
#cells=rownames(n2@assays$RNA@cells@.Data)
#colnames(n2_sparse)<-cells
#features=rownames(n2@assays$RNA@features@.Data)
#rownames(n2_sparse)<-features

#write.csv(n2_sparse, './filtered_sparse_matrices/n2_sparse.csv')

#n3_sparse=n3@assays$RNA@layers$counts
#cells=rownames(n3@assays$RNA@cells@.Data)
#colnames(n3_sparse)<-cells
#features=rownames(n3@assays$RNA@features@.Data)
#rownames(n3_sparse)<-features

#write.csv(n3_sparse, './filtered_sparse_matrices/n3_sparse.csv')

#n4_sparse=n4@assays$RNA@layers$counts
#cells=rownames(n4@assays$RNA@cells@.Data)
#colnames(n4_sparse)<-cells
#features=rownames(n4@assays$RNA@features@.Data)
#rownames(n4_sparse)<-features

#write.csv(n4_sparse, './filtered_sparse_matrices/n4_sparse.csv')

u1_sparse=u1@assays$RNA@layers$counts
cells=rownames(u1@assays$RNA@cells@.Data)
colnames(u1_sparse)<-cells
features=rownames(u1@assays$RNA@features@.Data)
rownames(u1_sparse)<-features

write.csv(u1_sparse, './filtered_sparse_matrices/u1_sparse.csv')
```




```{r doubletFinder for additional samples}
s1 <- standard_seurat_processing(s1)
ElbowPlot(s1)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(s1, dimensions)
s1 <- standard_clustering(s1,dimensions)
calculate_expected_doublets(s1@meta.data)
#Run DoubletFinder on dataset
#Input parameters are the prepped Seurat object, significant PCs, the optimal pK value calculated above, and the threshold for doublet+singlet prediction
#nExp can either be set based on the value calculated using calculate_expected_doublets() or using approximations based on number of cells loaded and reported multiplet rate from company
#For example, Pip-seq predicts a multiplet rate of 5% when loading 5,000 nuclei, so for 500 cells, you'd set nExp to 25
doublet_finder <- doubletFinder(seu = s1, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
#Save doublet finder results to metadata
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
s1<-AddMetaData(object = s1, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(s1$doublet_finder))
#Subset singlets
Idents(s1) <- "doublet_finder"
s1 <- subset(s1, idents = "Singlet")


#Execute the above commands on the remaining datasets:
#S2
s2 <- standard_seurat_processing(s2)
ElbowPlot(s2)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(s2, dimensions)
s2 <- standard_clustering(s2,dimensions)
calculate_expected_doublets(s2@meta.data)
doublet_finder <- doubletFinder(seu = s2, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
s2<-AddMetaData(object = s2, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(s2$doublet_finder))
Idents(s2) <- "doublet_finder"
s2 <- subset(s2, idents = "Singlet")

#S3
s3 <- standard_seurat_processing(s3)
ElbowPlot(s3)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(s3, dimensions)
s3 <- standard_clustering(s3,dimensions)
calculate_expected_doublets(s3@meta.data)
doublet_finder <- doubletFinder(seu = s3, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
s3<-AddMetaData(object = s3, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(s3$doublet_finder))
Idents(s3) <- "doublet_finder"
s3 <- subset(s3, idents = "Singlet")

#S4
s4 <- standard_seurat_processing(s4)
ElbowPlot(s4)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(s4, dimensions)
s4 <- standard_clustering(s4,dimensions)
calculate_expected_doublets(s4@meta.data)
doublet_finder <- doubletFinder(seu = s4, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
s4<-AddMetaData(object = s4, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(s4$doublet_finder))
Idents(s4) <- "doublet_finder"
s4 <- subset(s4, idents = "Singlet")

#S5
s5 <- standard_seurat_processing(s5)
ElbowPlot(s5)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(s5, dimensions)
s5 <- standard_clustering(s5,dimensions)
calculate_expected_doublets(s5@meta.data)
doublet_finder <- doubletFinder(seu = s5, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
s5<-AddMetaData(object = s5, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(s5$doublet_finder))
Idents(s5) <- "doublet_finder"
s5 <- subset(s5, idents = "Singlet")

#C1
c1 <- standard_seurat_processing(c1)
ElbowPlot(c1)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(c1, dimensions)
c1 <- standard_clustering(c1,dimensions)
calculate_expected_doublets(c1@meta.data)
doublet_finder <- doubletFinder(seu = c1, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
c1<-AddMetaData(object = c1, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(c1$doublet_finder))
Idents(c1) <- "doublet_finder"
c1 <- subset(c1, idents = "Singlet")

#C2
c2 <- standard_seurat_processing(c2)
ElbowPlot(c2)
#Set dimensions to inflection point on elbow plot
dimensions=10
pk_sweep(c2, dimensions)
c2 <- standard_clustering(c2,dimensions)
calculate_expected_doublets(c2@meta.data)
doublet_finder <- doubletFinder(seu = c2, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
c2<-AddMetaData(object = c2, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(c2$doublet_finder))
Idents(c2) <- "doublet_finder"
c2 <- subset(c2, idents = "Singlet")

#N1
n1 <- standard_seurat_processing(n1)
ElbowPlot(n1)
#Set dimensions to inflection point on elbow plot
dimensions=5
pk_sweep(n1, dimensions)
n1 <- standard_clustering(n1,dimensions)
calculate_expected_doublets(n1@meta.data)
doublet_finder <- doubletFinder(seu = n1, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
n1<-AddMetaData(object = n1, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(n1$doublet_finder))
Idents(n1) <- "doublet_finder"
n1 <- subset(n1, idents = "Singlet")

#N2
n2 <- standard_seurat_processing(n2)
ElbowPlot(n2)
#Set dimensions to inflection point on elbow plot
dimensions=5
pk_sweep(n2, dimensions)
n2 <- standard_clustering(n2,dimensions)
calculate_expected_doublets(n2@meta.data)
doublet_finder <- doubletFinder(seu = n2, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
n2<-AddMetaData(object = n2, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(n2$doublet_finder))
Idents(n2) <- "doublet_finder"
n2 <- subset(n2, idents = "Singlet")

#N3
n3 <- standard_seurat_processing(n3)
ElbowPlot(n3)
#Set dimensions to inflection point on elbow plot
dimensions=6
pk_sweep(n3, dimensions)
n3 <- standard_clustering(n3,dimensions)
calculate_expected_doublets(n3@meta.data)
doublet_finder <- doubletFinder(seu = n3, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
n3<-AddMetaData(object = n3, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(n3$doublet_finder))
Idents(n3) <- "doublet_finder"
n3 <- subset(n3, idents = "Singlet")

#N4
n4 <- standard_seurat_processing(n4)
ElbowPlot(n4)
#Set dimensions to inflection point on elbow plot
dimensions=7
pk_sweep(n4, dimensions)
n4 <- standard_clustering(n4,dimensions)
calculate_expected_doublets(n4@meta.data)
doublet_finder <- doubletFinder(seu = n4, 
                                   PCs = 1:dimensions, 
                                   pK = optimal.pk,
                                   nExp = nExp.poi.adj)
metadata <- doublet_finder@meta.data
colnames(metadata)[13] <- "doublet_finder"
n4<-AddMetaData(object = n4, metadata = metadata)
print('Total number of doublets and singlets detected in dataset:')
print(table(n4$doublet_finder))
Idents(n4) <- "doublet_finder"
n4 <- subset(n4, idents = "Singlet")
```